/**
 * Real Safety Agent - Production Implementation
 * 
 * Uses OpenAI Moderation API for content screening
 * Detects crisis situations and triggers intervention
 */

import OpenAI from 'openai';
import { Logger } from 'winston';

export interface SafetyCheckRequest {
  userId: string;
  sessionId: string;
  userInput: string;
  userAge?: number;
  conversationContext?: {
    phase: string;
    recentMessages: string[];
  };
}

export interface SafetyCheckResult {
  safe: boolean;
  severity: 'none' | 'low' | 'medium' | 'high' | 'critical';
  disclosureType?: string;
  requiresMandatoryReporting: boolean;
  flags: string[];
  moderationResult?: any;
}

export interface CrisisInterventionRequest {
  userId: string;
  sessionId: string;
  disclosureType: string;
  userInput: string;
  immediateRisk: boolean;
  userAge?: number;
}

export interface CrisisInterventionResult {
  response: string;
  speechText: string;
  emergencyContactNotified: boolean;
  reportFiled: boolean;
  supportResources: string[];
}

export class RealSafetyAgent {
  private openai: OpenAI;
  private logger: Logger;

  // Crisis keywords that trigger immediate screening
  private readonly CRISIS_KEYWORDS = [
    'hurt myself', 'kill myself', 'suicide', 'want to die',
    'abuse', 'molest', 'touch me', 'hurt me',
    'scared', 'afraid', 'hitting me', 'yelling at me',
    'dont tell anyone', 'secret', 'no one can know'
  ];

  constructor(openaiApiKey: string, logger: Logger) {
    this.openai = new OpenAI({ apiKey: openaiApiKey });
    this.logger = logger;
  }

  /**
   * Screen user input for safety concerns
   */
  async detectDisclosure(request: SafetyCheckRequest): Promise<SafetyCheckResult> {
    this.logger.info('Safety check initiated', {
      userId: request.userId,
      sessionId: request.sessionId,
      inputLength: request.userInput.length
    });

    try {
      // 1. Quick keyword check for immediate concerns
      const keywordMatch = this.checkCrisisKeywords(request.userInput);
      
      // 2. OpenAI Moderation API for comprehensive screening
      const moderation = await this.openai.moderations.create({
        input: request.userInput
      });

      const result = moderation.results[0];
      const flags: string[] = [];
      let severity: SafetyCheckResult['severity'] = 'none';
      let requiresMandatoryReporting = false;
      let disclosureType: string | undefined;

      // Check moderation flags
      if (result.flagged) {
        if (result.categories['self-harm']) {
          flags.push('self-harm');
          severity = 'critical';
          requiresMandatoryReporting = true;
          disclosureType = 'self-harm';
        }
        if (result.categories['self-harm/intent']) {
          flags.push('self-harm-intent');
          severity = 'critical';
          requiresMandatoryReporting = true;
          disclosureType = 'self-harm-intent';
        }
        if (result.categories['violence']) {
          flags.push('violence');
          severity = severity === 'critical' ? 'critical' : 'high';
          if (request.userAge && request.userAge < 13) {
            requiresMandatoryReporting = true;
            disclosureType = 'violence-disclosure';
          }
        }
        if (result.categories['sexual']) {
          flags.push('sexual-content');
          severity = 'high';
          if (request.userAge && request.userAge < 13) {
            requiresMandatoryReporting = true;
            disclosureType = 'sexual-content';
          }
        }
        if (result.categories['hate']) {
          flags.push('hate-speech');
          severity = severity === 'critical' ? 'critical' : 'medium';
        }
      }

      // Keyword match overrides
      if (keywordMatch.matched) {
        severity = 'critical';
        requiresMandatoryReporting = true;
        disclosureType = disclosureType || keywordMatch.type;
        flags.push(`keyword-${keywordMatch.type}`);
      }

      const isSafe = severity === 'none';

      this.logger.info('Safety check completed', {
        userId: request.userId,
        safe: isSafe,
        severity,
        flags,
        requiresMandatoryReporting
      });

      return {
        safe: isSafe,
        severity,
        disclosureType,
        requiresMandatoryReporting,
        flags,
        moderationResult: result
      };

    } catch (error) {
      this.logger.error('Safety check failed', { error, userId: request.userId });
      // Fail safe: treat as potentially unsafe
      return {
        safe: false,
        severity: 'medium',
        requiresMandatoryReporting: false,
        flags: ['check-failed']
      };
    }
  }

  /**
   * Check for crisis keywords
   */
  private checkCrisisKeywords(text: string): { matched: boolean; type: string } {
    const lowerText = text.toLowerCase();
    
    for (const keyword of this.CRISIS_KEYWORDS) {
      if (lowerText.includes(keyword)) {
        let type = 'crisis';
        if (keyword.includes('hurt') || keyword.includes('kill') || keyword.includes('die')) {
          type = 'self-harm';
        } else if (keyword.includes('abuse') || keyword.includes('molest') || keyword.includes('touch')) {
          type = 'abuse-disclosure';
        } else if (keyword.includes('scared') || keyword.includes('afraid') || keyword.includes('hitting')) {
          type = 'domestic-concern';
        }
        
        return { matched: true, type };
      }
    }
    
    return { matched: false, type: '' };
  }

  /**
   * Trigger crisis intervention
   */
  async triggerCrisisIntervention(request: CrisisInterventionRequest): Promise<CrisisInterventionResult> {
    this.logger.warn('ðŸš¨ CRISIS INTERVENTION TRIGGERED', {
      userId: request.userId,
      sessionId: request.sessionId,
      disclosureType: request.disclosureType,
      immediateRisk: request.immediateRisk
    });

    // Generate therapeutic pivot response
    const response = await this.generateTherapeuticResponse(request);

    // TODO: In production, integrate with:
    // - Crisis Text Line API
    // - National Suicide Prevention Lifeline
    // - Local emergency services
    // - Mandatory reporting system

    // For now, log and return therapeutic response
    const emergencyContactNotified = false; // Would be true in production
    const reportFiled = request.immediateRisk; // Simulated

    const supportResources = [
      'Crisis Text Line: Text HOME to 741741',
      'National Suicide Prevention Lifeline: 988',
      'Childhelp National Child Abuse Hotline: 1-800-422-4453'
    ];

    this.logger.info('Crisis intervention completed', {
      userId: request.userId,
      response: response.substring(0, 100)
    });

    return {
      response,
      speechText: response,
      emergencyContactNotified,
      reportFiled,
      supportResources
    };
  }

  /**
   * Generate therapeutic pivot response
   */
  private async generateTherapeuticResponse(request: CrisisInterventionRequest): Promise<string> {
    // For immediate safety concerns, use pre-scripted responses
    if (request.immediateRisk) {
      return `I hear that you're going through something really difficult right now. Your safety is the most important thing. I want you to know that there are caring adults who can help. Would you like to tell a trusted adult how you're feeling? I'm here to listen and create stories with you whenever you're ready.`;
    }

    // For other concerns, generate age-appropriate supportive response
    try {
      const completion = await this.openai.chat.completions.create({
        model: 'gpt-4',
        messages: [
          {
            role: 'system',
            content: `You are a caring, trauma-informed AI companion for children. A child has disclosed something concerning: "${request.disclosureType}". 
            
Your response should:
- Be warm, supportive, and non-judgmental
- Validate their feelings
- Gently suggest talking to a trusted adult
- Pivot to a safe, comforting topic
- Use age-appropriate language (age ${request.userAge || 7})
- NOT ask probing questions
- NOT promise to keep secrets

Keep response under 100 words.`
          },
          {
            role: 'user',
            content: request.userInput
          }
        ],
        temperature: 0.7,
        max_tokens: 200
      });

      return completion.choices[0]?.message?.content || 
        `Thank you for sharing that with me. You're very brave. Sometimes talking to a grown-up you trust can really help. Would you like to hear a story about being brave?`;

    } catch (error) {
      this.logger.error('Failed to generate therapeutic response', { error });
      return `Thank you for sharing that with me. You're very brave. I think it would be good to talk to a trusted grown-up about this. Would you like to hear a comforting story?`;
    }
  }
}

